{"ast":null,"code":"\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.LexerAdapter = void 0;\n\nvar parser_1 = require(\"../parser\");\n/**\n * Trait responsible abstracting over the interaction with Lexer output (Token vector).\n *\n * This could be generalized to support other kinds of lexers, e.g.\n * - Just in Time Lexing / Lexer-Less parsing.\n * - Streaming Lexer.\n */\n\n\nvar LexerAdapter =\n/** @class */\nfunction () {\n  function LexerAdapter() {}\n\n  LexerAdapter.prototype.initLexerAdapter = function () {\n    this.tokVector = [];\n    this.tokVectorLength = 0;\n    this.currIdx = -1;\n  };\n\n  Object.defineProperty(LexerAdapter.prototype, \"input\", {\n    get: function () {\n      return this.tokVector;\n    },\n    set: function (newInput) {\n      // @ts-ignore - `this parameter` not supported in setters/getters\n      //   - https://www.typescriptlang.org/docs/handbook/functions.html#this-parameters\n      if (this.selfAnalysisDone !== true) {\n        throw Error(\"Missing <performSelfAnalysis> invocation at the end of the Parser's constructor.\");\n      } // @ts-ignore - `this parameter` not supported in setters/getters\n      //   - https://www.typescriptlang.org/docs/handbook/functions.html#this-parameters\n\n\n      this.reset();\n      this.tokVector = newInput;\n      this.tokVectorLength = newInput.length;\n    },\n    enumerable: false,\n    configurable: true\n  }); // skips a token and returns the next token\n\n  LexerAdapter.prototype.SKIP_TOKEN = function () {\n    if (this.currIdx <= this.tokVector.length - 2) {\n      this.consumeToken();\n      return this.LA(1);\n    } else {\n      return parser_1.END_OF_FILE;\n    }\n  }; // Lexer (accessing Token vector) related methods which can be overridden to implement lazy lexers\n  // or lexers dependent on parser context.\n\n\n  LexerAdapter.prototype.LA = function (howMuch) {\n    var soughtIdx = this.currIdx + howMuch;\n\n    if (soughtIdx < 0 || this.tokVectorLength <= soughtIdx) {\n      return parser_1.END_OF_FILE;\n    } else {\n      return this.tokVector[soughtIdx];\n    }\n  };\n\n  LexerAdapter.prototype.consumeToken = function () {\n    this.currIdx++;\n  };\n\n  LexerAdapter.prototype.exportLexerState = function () {\n    return this.currIdx;\n  };\n\n  LexerAdapter.prototype.importLexerState = function (newState) {\n    this.currIdx = newState;\n  };\n\n  LexerAdapter.prototype.resetLexerState = function () {\n    this.currIdx = -1;\n  };\n\n  LexerAdapter.prototype.moveToTerminatedState = function () {\n    this.currIdx = this.tokVector.length - 1;\n  };\n\n  LexerAdapter.prototype.getLexerPosition = function () {\n    return this.exportLexerState();\n  };\n\n  return LexerAdapter;\n}();\n\nexports.LexerAdapter = LexerAdapter;","map":{"version":3,"sources":["/Users/charlie/Desktop/SneakViz/node_modules/chevrotain/src/parse/parser/traits/lexer_adapter.ts"],"names":[],"mappings":";;;;;;;AAAA,IAAA,QAAA,GAAA,OAAA,CAAA,WAAA,CAAA;AAIA;;;;;;AAMG;;;AACH,IAAA,YAAA;AAAA;AAAA,YAAA;AAAA,WAAA,YAAA,GAAA,CA0EC;;AArEC,EAAA,YAAA,CAAA,SAAA,CAAA,gBAAA,GAAA,YAAA;AACE,SAAK,SAAL,GAAiB,EAAjB;AACA,SAAK,eAAL,GAAuB,CAAvB;AACA,SAAK,OAAL,GAAe,CAAC,CAAhB;AACD,GAJD;;AAMA,EAAA,MAAA,CAAA,cAAA,CAAI,YAAA,CAAA,SAAJ,EAAI,OAAJ,EAAS;SAeT,YAAA;AACE,aAAO,KAAK,SAAZ;AACD,KAjBQ;SAAT,UAAU,QAAV,EAA4B;AAC1B;AACA;AACA,UAAI,KAAK,gBAAL,KAA0B,IAA9B,EAAoC;AAClC,cAAM,KAAK,CACT,kFADS,CAAX;AAGD,OAPyB,CAQ1B;AACA;;;AACA,WAAK,KAAL;AACA,WAAK,SAAL,GAAiB,QAAjB;AACA,WAAK,eAAL,GAAuB,QAAQ,CAAC,MAAhC;AACD,KAbQ;qBAAA;;AAAA,GAAT,EAXF,CA8BE;;AACA,EAAA,YAAA,CAAA,SAAA,CAAA,UAAA,GAAA,YAAA;AACE,QAAI,KAAK,OAAL,IAAgB,KAAK,SAAL,CAAe,MAAf,GAAwB,CAA5C,EAA+C;AAC7C,WAAK,YAAL;AACA,aAAO,KAAK,EAAL,CAAQ,CAAR,CAAP;AACD,KAHD,MAGO;AACL,aAAO,QAAA,CAAA,WAAP;AACD;AACF,GAPD,CA/BF,CAwCE;AACA;;;AACA,EAAA,YAAA,CAAA,SAAA,CAAA,EAAA,GAAA,UAAwB,OAAxB,EAAuC;AACrC,QAAM,SAAS,GAAG,KAAK,OAAL,GAAe,OAAjC;;AACA,QAAI,SAAS,GAAG,CAAZ,IAAiB,KAAK,eAAL,IAAwB,SAA7C,EAAwD;AACtD,aAAO,QAAA,CAAA,WAAP;AACD,KAFD,MAEO;AACL,aAAO,KAAK,SAAL,CAAe,SAAf,CAAP;AACD;AACF,GAPD;;AASA,EAAA,YAAA,CAAA,SAAA,CAAA,YAAA,GAAA,YAAA;AACE,SAAK,OAAL;AACD,GAFD;;AAIA,EAAA,YAAA,CAAA,SAAA,CAAA,gBAAA,GAAA,YAAA;AACE,WAAO,KAAK,OAAZ;AACD,GAFD;;AAIA,EAAA,YAAA,CAAA,SAAA,CAAA,gBAAA,GAAA,UAAsC,QAAtC,EAAsD;AACpD,SAAK,OAAL,GAAe,QAAf;AACD,GAFD;;AAIA,EAAA,YAAA,CAAA,SAAA,CAAA,eAAA,GAAA,YAAA;AACE,SAAK,OAAL,GAAe,CAAC,CAAhB;AACD,GAFD;;AAIA,EAAA,YAAA,CAAA,SAAA,CAAA,qBAAA,GAAA,YAAA;AACE,SAAK,OAAL,GAAe,KAAK,SAAL,CAAe,MAAf,GAAwB,CAAvC;AACD,GAFD;;AAIA,EAAA,YAAA,CAAA,SAAA,CAAA,gBAAA,GAAA,YAAA;AACE,WAAO,KAAK,gBAAL,EAAP;AACD,GAFD;;AAGF,SAAA,YAAA;AAAC,CA1ED,EAAA;;AAAa,OAAA,CAAA,YAAA,GAAA,YAAA","sourcesContent":["import { END_OF_FILE } from \"../parser\"\nimport { IToken } from \"@chevrotain/types\"\nimport { MixedInParser } from \"./parser_traits\"\n\n/**\n * Trait responsible abstracting over the interaction with Lexer output (Token vector).\n *\n * This could be generalized to support other kinds of lexers, e.g.\n * - Just in Time Lexing / Lexer-Less parsing.\n * - Streaming Lexer.\n */\nexport class LexerAdapter {\n  tokVector: IToken[]\n  tokVectorLength\n  currIdx: number\n\n  initLexerAdapter() {\n    this.tokVector = []\n    this.tokVectorLength = 0\n    this.currIdx = -1\n  }\n\n  set input(newInput: IToken[]) {\n    // @ts-ignore - `this parameter` not supported in setters/getters\n    //   - https://www.typescriptlang.org/docs/handbook/functions.html#this-parameters\n    if (this.selfAnalysisDone !== true) {\n      throw Error(\n        `Missing <performSelfAnalysis> invocation at the end of the Parser's constructor.`\n      )\n    }\n    // @ts-ignore - `this parameter` not supported in setters/getters\n    //   - https://www.typescriptlang.org/docs/handbook/functions.html#this-parameters\n    this.reset()\n    this.tokVector = newInput\n    this.tokVectorLength = newInput.length\n  }\n\n  get input(): IToken[] {\n    return this.tokVector\n  }\n\n  // skips a token and returns the next token\n  SKIP_TOKEN(this: MixedInParser): IToken {\n    if (this.currIdx <= this.tokVector.length - 2) {\n      this.consumeToken()\n      return this.LA(1)\n    } else {\n      return END_OF_FILE\n    }\n  }\n\n  // Lexer (accessing Token vector) related methods which can be overridden to implement lazy lexers\n  // or lexers dependent on parser context.\n  LA(this: MixedInParser, howMuch: number): IToken {\n    const soughtIdx = this.currIdx + howMuch\n    if (soughtIdx < 0 || this.tokVectorLength <= soughtIdx) {\n      return END_OF_FILE\n    } else {\n      return this.tokVector[soughtIdx]\n    }\n  }\n\n  consumeToken(this: MixedInParser) {\n    this.currIdx++\n  }\n\n  exportLexerState(this: MixedInParser): number {\n    return this.currIdx\n  }\n\n  importLexerState(this: MixedInParser, newState: number) {\n    this.currIdx = newState\n  }\n\n  resetLexerState(this: MixedInParser): void {\n    this.currIdx = -1\n  }\n\n  moveToTerminatedState(this: MixedInParser): void {\n    this.currIdx = this.tokVector.length - 1\n  }\n\n  getLexerPosition(this: MixedInParser): number {\n    return this.exportLexerState()\n  }\n}\n"]},"metadata":{},"sourceType":"script"}